{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook helps with generating monthly data, including features for airport congestion level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:12.708912Z",
     "start_time": "2020-05-17T12:58:12.155384Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# be able to view all columns of dataframes\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an empty CSV file to maintain the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:12.714864Z",
     "start_time": "2020-05-17T12:58:12.710896Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset_path = 'C:\\\\Users\\\\lis\\\\repos\\\\flight_duration_prediction\\\\data\\\\raw\\\\'\n",
    "train_dataset_name = 'training_data_ATL.csv'\n",
    "\n",
    "# Create the empty file for once only\n",
    "#with open(train_dataset_path + train_dataset_name, \"w\") as my_empty_csv:\n",
    "#    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:12.721311Z",
     "start_time": "2020-05-17T12:58:12.716848Z"
    }
   },
   "outputs": [],
   "source": [
    "# flag for header in csv file\n",
    "# be true only for the first file\n",
    "first_df_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locate raw CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:12.735200Z",
     "start_time": "2020-05-17T12:58:12.723296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "data_folder = '../data/raw/training_data/'\n",
    "file_list = os.listdir(data_folder)\n",
    "print(len(file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:17.424813Z",
     "start_time": "2020-05-17T12:58:12.737681Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder + file_list[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:17.433741Z",
     "start_time": "2020-05-17T12:58:17.426301Z"
    }
   },
   "outputs": [],
   "source": [
    "# irrelvant fields to the project\n",
    "field_list = ['FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest',\\\n",
    "              'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID',\\\n",
    "              'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum',  'Div2Airport', \\\n",
    "              'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff',\\\n",
    "              'Div2TailNum', 'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime',\\\n",
    "              'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', \\\n",
    "              'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', \\\n",
    "              'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', \\\n",
    "              'Div5WheelsOff', 'Div5TailNum', 'Cancelled', 'CancellationCode', 'Diverted']\n",
    "\n",
    "# CRSArrTime is an int with max four digits. Append zeros to make all consist of 4 digits\n",
    "# then convert to a datetime object\n",
    "def format_time(CRSTime):\n",
    "    time_str = str(CRSTime)\n",
    "    formatted_time_str = time_str.zfill(4)\n",
    "    time = pd.to_datetime(formatted_time_str, format=\"%H%M\")\n",
    "    return time\n",
    "\n",
    "one_day = pd.Timedelta('1 days')\n",
    "five_min = pd.Timedelta('5 minutes')\n",
    "ten_min = pd.Timedelta('10 minutes')\n",
    "fifteen_min = pd.Timedelta('15 minutes')\n",
    "twenty_min = pd.Timedelta('20 minutes')\n",
    "twenty5_min = pd.Timedelta('25 minutes')\n",
    "thirty_min = pd.Timedelta('30 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:17.760784Z",
     "start_time": "2020-05-17T12:58:17.436222Z"
    }
   },
   "outputs": [],
   "source": [
    "not_cancelled = df['Cancelled']==0\n",
    "not_diverted = df['Diverted']==0\n",
    "normal_flights = not_cancelled & not_diverted\n",
    "\n",
    "flights = df[normal_flights]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, drop columns related to cancellation or divertion and irrelevant column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:31.000209Z",
     "start_time": "2020-05-17T12:58:17.762584Z"
    }
   },
   "outputs": [],
   "source": [
    "for field in field_list:\n",
    "    flights = flights.drop(labels=field, axis=1)\n",
    "    \n",
    "flights.drop(flights.columns[flights.columns.str.contains('unnamed', case=False)], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all flight traffic in ATL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:31.040427Z",
     "start_time": "2020-05-17T12:58:31.002194Z"
    }
   },
   "outputs": [],
   "source": [
    "atl_id = 10397\n",
    "arrivals = flights[flights['DestAirportID']==atl_id]\n",
    "departures = flights[flights['OriginAirportID']==atl_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process arrivals and departures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:43.276076Z",
     "start_time": "2020-05-17T12:58:31.041873Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert FlightDate to a datetime object\n",
    "arrivals['FlightDate'] = pd.to_datetime(arrivals['FlightDate'])\n",
    "departures['FlightDate'] = pd.to_datetime(departures['FlightDate'])\n",
    "\n",
    "# convert CRS times to datetime objects\n",
    "arrivals['CRSArrTime'] = arrivals['CRSArrTime'].apply(lambda x: format_time(x)).dt.time\n",
    "departures['CRSDepTime'] = departures['CRSDepTime'].apply(lambda x: format_time(x)).dt.time\n",
    "\n",
    "# for arrival flights, the flight date may not be equal to ARRIVAL date\n",
    "# e.g., depart at origin airport at 2350 1 Jan, then arrived at ATL at 0340 2 Jan at ATL\n",
    "# add a column called ArrivalDate in arrivals dataframe\n",
    "# initialize the column values to be the same as FlightDate\n",
    "arrivals['ArrivalDate'] = arrivals['FlightDate']\n",
    "\n",
    "# for the arrival flights with CRSArrTime < CRSDepTime (convert CRSDepTime to a datetime object first)\n",
    "# let ArrivalDate be FlightDate + 1\n",
    "arrivals['CRSDepTime'] = arrivals['CRSDepTime'].apply(lambda x: format_time(x)).dt.time\n",
    "arrivals.loc[arrivals.CRSArrTime < arrivals.CRSDepTime, \"ArrivalDate\"] = arrivals['FlightDate'] + one_day\n",
    "\n",
    "# ARR_Flight_SLDT is obtained by concatenating ArrivalDate and CRSArrTime\n",
    "arrivals['ARR_Flight_SLDT'] = arrivals.apply(lambda r: pd.datetime.combine(r['ArrivalDate'], r['CRSArrTime']), 1)\n",
    "\n",
    "# concatenate departure date and time to generate STOT first\n",
    "departures['DEP_Flight_STOT'] = departures.apply(lambda r: pd.datetime.combine(r['FlightDate'], r['CRSDepTime']), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:43.297859Z",
     "start_time": "2020-05-17T12:58:43.277522Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize new feature columns in arrivals df\n",
    "feature_list = ['Num_Arr_SLDT-30', 'Num_Arr_SLDT-25', 'Num_Arr_SLDT-20', 'Num_Arr_SLDT-15', 'Num_Arr_SLDT-10',\\\n",
    "                'Num_Arr_SLDT-5', 'Num_Arr_SLDT-0', 'Num_Arr_SLDT+5', 'Num_Arr_SLDT+10', 'Num_Arr_SLDT+15',\\\n",
    "                'Num_Arr_SLDT+20', 'Num_Arr_SLDT+25', 'Num_Dep_SLDT-30', 'Num_Dep_SLDT-25', 'Num_Dep_SLDT-20',\\\n",
    "                'Num_Dep_SLDT-15', 'Num_Dep_SLDT-10', 'Num_Dep_SLDT-5', 'Num_Dep_SLDT-0', 'Num_Dep_SLDT+5',\\\n",
    "                'Num_Dep_SLDT+10', 'Num_Dep_SLDT+15', 'Num_Dep_SLDT+20', 'Num_Dep_SLDT+25']\n",
    "\n",
    "for feature in feature_list:\n",
    "    arrivals[feature] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new features for arrival dataframe to represent airport congestion rate:\\\n",
    "Number of flights arrived or departed within SLDT-30min and SLDT+30min, binned at 5min intervals.\\\n",
    "Hence, the number of new features is (30+30)/5*2 = 24.\\\n",
    "Column name example: Num_Arr_SLDT-30\\\n",
    "i.e. Number of arrival flights in the interval of SLDT-30min and SLDT-25min at ATL airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T12:58:43.329603Z",
     "start_time": "2020-05-17T12:58:43.299842Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate the dep STOT df and stot series\n",
    "dep_flight_STOT = departures[['FlightDate','DEP_Flight_STOT']]\n",
    "stot = dep_flight_STOT['DEP_Flight_STOT']\n",
    "\n",
    "# generate the arr SLDT df and sldt series\n",
    "arr_flight_SLDT = arrivals[['FlightDate','ARR_Flight_SLDT']]\n",
    "sldt = arr_flight_SLDT['ARR_Flight_SLDT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T13:13:32.244762Z",
     "start_time": "2020-05-17T12:58:43.331587Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['Num_Dep_SLDT-30', 'Num_Dep_SLDT-25', 'Num_Dep_SLDT-20',\\\n",
    "            'Num_Dep_SLDT-15', 'Num_Dep_SLDT-10', 'Num_Dep_SLDT-5', 'Num_Dep_SLDT-0', 'Num_Dep_SLDT+5',\\\n",
    "            'Num_Dep_SLDT+10', 'Num_Dep_SLDT+15', 'Num_Dep_SLDT+20', 'Num_Dep_SLDT+25']\n",
    "\n",
    "features2 = ['Num_Arr_SLDT-30', 'Num_Arr_SLDT-25', 'Num_Arr_SLDT-20', 'Num_Arr_SLDT-15', 'Num_Arr_SLDT-10',\\\n",
    "             'Num_Arr_SLDT-5', 'Num_Arr_SLDT-0', 'Num_Arr_SLDT+5', 'Num_Arr_SLDT+10', 'Num_Arr_SLDT+15',\\\n",
    "             'Num_Arr_SLDT+20', 'Num_Arr_SLDT+25']\n",
    "\n",
    "# loop through every arrival flight in arrivals df\n",
    "for i in arrivals.index:\n",
    "    \n",
    "    this_SLDT = arrivals['ARR_Flight_SLDT'][i]\n",
    "    \n",
    "    minus_30 = this_SLDT - thirty_min\n",
    "    minus_25 = this_SLDT - twenty5_min\n",
    "    minus_20 = this_SLDT - twenty_min\n",
    "    minus_15 = this_SLDT - fifteen_min\n",
    "    minus_10 = this_SLDT - ten_min\n",
    "    minus_5 = this_SLDT + five_min\n",
    "    plus_30 = this_SLDT + thirty_min\n",
    "    plus_25 = this_SLDT + twenty5_min\n",
    "    plus_20 = this_SLDT + twenty_min\n",
    "    plus_15 = this_SLDT + fifteen_min\n",
    "    plus_10 = this_SLDT + ten_min\n",
    "    plus_5 = this_SLDT + five_min\n",
    "    \n",
    "    time_list = [minus_30, minus_25, minus_20, minus_15, minus_10, minus_5, this_SLDT,\\\n",
    "                 plus_5, plus_10, plus_15, plus_20, plus_25, plus_30]\n",
    "\n",
    "    for j in range(len(time_list)-1):\n",
    "        mask_dep = (time_list[j] <= stot) & (stot < time_list[j+1])\n",
    "        arrivals[features[j]][i] = dep_flight_STOT.loc[mask_dep].shape[0]\n",
    "        \n",
    "        mask_arr = (time_list[j] <= sldt) & (sldt < time_list[j+1])\n",
    "        arrivals[features2[j]][i] = arr_flight_SLDT.loc[mask_arr].shape[0]\n",
    "        \n",
    "# to remove the arrival flight itself from the number of arrival flights at its SLDT\n",
    "arrivals['Num_Arr_SLDT-0'] = arrivals['Num_Arr_SLDT-0'] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T13:13:34.926150Z",
     "start_time": "2020-05-17T13:13:32.247213Z"
    }
   },
   "outputs": [],
   "source": [
    "# append the df to csv file\n",
    "arrivals.to_csv(train_dataset_path + train_dataset_name, mode='a', header=first_df_flag)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
